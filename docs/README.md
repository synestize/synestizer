![Synestizer logo](https://synestize.github.io/synestizer/media/synestizer_logo_50x50.png)


# Synestizer

> „Just open the window...”  J.Cage and focus on listening to what emerges outside.
- Cage

> „It's time to open the digital window and listen colorwise.”
- Koenig


This document explains the idea and function of the synestizer project at [synestizer.com](http://synestizer.com) and [listentocolors.net](https://listentocolors.net).
A webapp to listen to the data flow of the camera-imagery.

## What is a Synestizer?

The word Synestizer is a portmanteau of *synthesizer* ) and *synaesthesia*. Synestizer sonifies live camera imagery, tickling the synapses between your ears and eyes.

Music visualisers and screensavers already translate sound into graphics.
But synestizer does the opposite, translating Red, Green and Blue values to sound.
For this effect, or let’s say „sense“, there are new methods and techniques explored, developed and spread online.
That's why it is time to open the digital window and listen through it.

## Why working hard to invent a Synestizer?

Since Cameras can measure Red Green Blue (RGB) values and its luminosity in given situations they correspond to the RGB sensitivity of the cones of the eyes. Since audible and visible frequencies differ in wavelength only, there might be a relation of some sort. The fascinating part of the synestizer is to come up with sonifying techniques to suggest an instant soundtrack matching exactly what you see in front of you right now. Imagining an induced synesthesia by technical means already on an average desk or pocket computer device.

Can this webapp contribute to the moment? Or at least extend the “obvious” with an interesting „odor” or an ambient-lighting but with audible means. In the future we might get used to an add-on sonification to our daily routines. Like a personal contextual-sound-DJ or as an automated soundtrack-maker for movies. Maybe just to pimp a daily situation or create an acoustic ambiance for a room.
A challenge for the synestizer-project is to generate ad-hoc compositions that are fitting to the situation you are or better said your camera is in, and on top surprise you again and again.


![color sensitivity of the eye](https://synestize.github.io/synestizer/media/Color_Sensitivity.jpg)

Can this webapp contribute to the moment? Or at least extend the “obvious” with an interesting „odor”
or an ambient-lighting but with audible means.
In the future we might get used to an add-on sonification to our daily routines. Like a personal contextual-sound-DJ or as an automated soundtrack-maker for movies.
Maybe just to pimp a daily situation or create an acoustic ambiance for a room.

A challenge for the synestizer-project is to generate ad-hoc compositions that are fitting to the situation you are or better said your camera is in, and on top surprise you again and again.


## Who develops the synestizer?

Sound artist [Kaspar König](http://www.kasparkoenig.com) loves experimenting with analog and digital techniques to sonify the context imminently surrounding us.
His interest in interpreting colours, patterns, materials and most recently also wind as an actor to map sound lead to the development of the initial version of the synestizer.
Now the group is growing and there are new people interested in the project, and we have opened up the code to invite even more to join us.
Users and artists are welcome to experiment with, and developers, to modify, this thing.

Synestizer is currently maintained by

* [Dan MacKinlay](https://danmackinlay.name/) (UNSW)
* [Christoph Stähli](http://www.stahlnow.com) 
* [Kaspar König](https://kasparkoenig.com) (ZHdK)

Support has been provided by

* [Sonic Sonic Skills research project at the Faculty of Arts and Social Sciences of Maastricht University](http://exhibition.sonicskills.org/exhibition/booth2/the-synestizer/), coordinated by Prof. Karin Bijsterveld.
* [Prof. Peter Kiefer](http://www.musik.uni-mainz.de/741_DEU_HTML.php) from the Johannes Gutenberg University in Mainz
* [Prof. Florian Dombois](http://www.floriandombois.net/) and [Prof. German Toro Perez](http://www.toro-perez.com/) from the [ZHdK]( https://www.zhdk.ch/) 

You can find our lectures/performances [here](https://www.zhdk.ch/?vorlesungsverzeichnis&semester_id=140409&cc_page_id=1802&course_id=165301).

Want to join us?
See [github](https://github.com/synestize/synestizer) for the source code.

Ideas or interest in participation? Just write us an email at [synestizer@gmail.com](mailto:synestizer@gmail.com)


## Privacy

Although you have to accept the general use of the camera and microphone in the browser, we do not collect or even receive any data from it.
You can verify this by going off- and online again and see that, once the app is downloaded, it doesn't use the network connection.
Or [inspect the source code](https://github.com/synestize/synestizer).

The sound and imagery is not captured.
The (voluntary) option of saving preferences, patches, settings or mappings online at [synestizer.com](http://synestizer.com) may be added in a future version.

We do use Google Analytics to set cookies to analyse the origin of viewers of the web-page. This information is not associated with user-name or any other usage information.
